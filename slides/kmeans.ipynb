{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduktion til k-means clustering\n",
    "## Af Henrik Sterner (hst@nextkbh.dk)\n",
    "I denne notebook (jupyter) vil vi introducere k-means clustering. Vi vil først introducere konceptet clustering og derefter introducere k-means clustering. Vi vil til sidst introducere et eksempel på k-means clustering.\n",
    "\n",
    "### Clustering eller klasseinddeling\n",
    "Clustering er en metode til at gruppere data i forskellige grupper. Disse grupper kaldes for klasse eller cluster. Clustering er en form for unsupervised learning, da vi ikke har nogen labels på vores data. \n",
    "Vi kan derfor ikke bruge supervised learning metoder til at løse problemet.\n",
    "\n",
    "Den algoritme som vi vil introducere i denne notebook er k-means clustering. K-means clustering er en metode til at gruppere data i k grupper. K-means clustering er en af de mest brugte metoder til clustering.\n",
    "Det er en relativt simpel algoritme, som er nem at implementere og som er hurtig til at køre. \n",
    "Samtidig er den også effektiv til at finde grupper i data.\n",
    "\n",
    "I k-means clustering er k et parameter, som vi selv skal vælge. Det er derfor vigtigt at vælge et passende k. Vi vil i denne notebook introducere en metode til at vælge k.\n",
    "\n",
    "Anvendelser af k-means clustering er mange. Her er nogle eksempler:\n",
    "* Segmentering af kunder i forskellige grupper\n",
    "* Segmentering af billeder i forskellige grupper\n",
    "* Segmentering af tekster i forskellige grupper\n",
    "* Segmentering af lyd i forskellige grupper\n",
    "* Segmentering af gener i forskellige grupper\n",
    "* Segmentering af genererede data i forskellige grupper\n",
    "* Segmentering af klimadata i forskellige grupper\n",
    "* Segmentering af aktiedata i forskellige grupper\n",
    "* Segmentering af kryptodata i forskellige grupper\n",
    "* Segmentering af klimadata i forskellige grupper\n",
    "* Osv. \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering algoritmen\n",
    "K-means clustering algoritmen er en iterativ algoritme. Det betyder at den kører i flere iterationer. I hver iteration opdateres klassecentrene.\n",
    "\n",
    "K-means clustering algoritmen er en algoritme, som forsøger at minimere afstanden mellem datapunkterne og klassecentrene. Det betyder at datapunkterne i en klasse er tættere på klassecentret end datapunkterne i de andre klasser.\n",
    "\n",
    "Antag vi har givet et datasæt med n datapunkter i planen. Punkterne er på formen: $P_i = (x_{i}, y_{i})$ for $i = 1, 2, ..., n$. Vi ønsker at gruppere datapunkterne i k grupper. Vi skal derfor finde k klassecentre: $c_j = (c_{j1}, c_{j2})$ for $j = 1, 2, ..., k$.\n",
    "Disse klassecentre er punkter i planen. Vi skal finde de k klassecentre, som minimerer afstanden mellem datapunkterne og klassecentrene.\n",
    "\n",
    "Lad os starte med at formulere en prosakode version af k-means clustering algoritmen:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prosakode til k-means clustering algoritmen:\n",
    "1. Vælg k klassecentre tilfældigt\n",
    "2. For hvert datapunkt $P_i$:\n",
    "    1. Beregn afstanden mellem $P_i$ og alle klassecentrene\n",
    "    2. Vælg det klassecenter, som $P_i$ er tættest på\n",
    "    3. Tilføj $P_i$ til den klasse, som klassecentret tilhører\n",
    "    4. Gentag for alle datapunkter\n",
    "    5. Opdater klassecentrene ved at beregne gennemsnittet af alle datapunkter i hver klasse\n",
    "3. Gentag fra 1. indtil klassecentrene ikke ændrer sig\n",
    "4. Returner klassecentrene og klasserne\n",
    "\n",
    "Lad os nu formulere en mere detaljeret k-means clustering algoritmen som en algoritme i pseudokode:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Et datasæt med n datapunkter i planen: $P_i = (x_{i}, y_{i})$ for $i = 1, 2, ..., n$ og antallet af klassecentre k.\n",
    "\n",
    "Output: k klassecentre: $c_j = (c_{j1}, c_{j2})$ for $j = 1, 2, ..., k$.\n",
    "\n",
    "1. Vælg k tilfældige klassecentre: $c_j = (c_{j1}, c_{j2})$ for $j = 1, 2, ..., k$.\n",
    "2. For hvert datapunkt $P_i = (x_{i}, y_{i})$ for $i = 1, 2, ..., n$:\n",
    "    1. Beregn afstanden mellem datapunktet og hvert klassecenter: $d_{ij} = \\sqrt{(x_{i} - c_{j1})^2 + (y_{i} - c_{j2})^2}$ for $j = 1, 2, ..., k$.\n",
    "    2. Find det klassecenter, som datapunktet er tættest på: $c_{j} = argmin_{j} d_{ij}$.\n",
    "    3. Tilføj datapunktet til klasse j: $C_j = C_j \\cup \\{P_i\\}$.\n",
    "    4. Gentag for hvert datapunkt.\n",
    "    5. For hvert klassecenter $c_j = (c_{j1}, c_{j2})$ for $j = 1, 2, ..., k$:\n",
    "        1. Beregn det nye klassecenter: $c_j = (\\frac{1}{|C_j|}\\sum_{P_i \\in C_j} x_i, \\frac{1}{|C_j|}\\sum_{P_i \\in C_j} y_i)$.\n",
    "        2. Gentag for hvert klassecenter.\n",
    "        3. Gentag fra trin 2 indtil klassecentrene ikke ændrer sig.\n",
    "        4. Returner klassecentrene.\n",
    "  1. Gentag fra trin 1 indtil klassecentrene ikke ændrer sig.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementering af k-means clustering algoritmen i 2d\n",
    "Vi vil nu implementere k-means clustering algoritmen i 2d. Vi vil først implementere en funktion til at finde det klassecenter, som et givent punkt er tættest på. Vi vil derefter implementere en funktion til at opdatere klassecentrene. Vi vil til sidst implementere en funktion til at køre k-means clustering algoritmen.\n",
    "\n",
    "Vi vil først importere de nødvendige biblioteker:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "Vi vil nu implementere en funktion til at finde det klassecenter, som et givent punkt er tættest på. Funktionen skal tage et punkt og en liste af klassecentre som input. Funktionen skal returnere det klassecenter, som punktet er tættest på.\n",
    "\n",
    "```python\n",
    "def find_closest_centroid(point, centroids):    \n",
    "    closest_centroid = None\n",
    "    closest_distance = None\n",
    "    for centroid in centroids:\n",
    "        distance = np.sqrt((point[0] - centroid[0]) ** 2 + (point[1] - centroid[1]) ** 2)\n",
    "        if closest_distance is None or distance < closest_distance:\n",
    "            closest_distance = distance\n",
    "            closest_centroid = centroid\n",
    "    return closest_centroid\n",
    "```\n",
    "I ovenstående kode har vi lavet en funktion, som tager et punkt og en liste af klassecentre som input. Funktionen returnerer det klassecenter, som punktet er tættest på. Vi har brugt en for-løkke til at iterere over alle klassecentrene. Vi har beregnet afstanden mellem punktet og klassecentret. Vi har gemt det klassecenter, som punktet er tættest på. Vi har returneret det klassecenter, som punktet er tættest på.\n",
    "\n",
    "Vi vil nu teste funktionen:\n",
    "\n",
    "```python\n",
    "point = (1, 1)\n",
    "centroids = [(0, 0), (2, 2), (3, 3)]\n",
    "closest_centroid = find_closest_centroid(point, centroids)\n",
    "print(closest_centroid)\n",
    "```\n",
    "Vi får følgende output:\n",
    "```python\n",
    "(0, 0)\n",
    "```\n",
    "\n",
    "Vi vil nu implementere en funktion til at opdatere klassecentrene. Funktionen skal tage en liste af klassecentre og en liste af klasser som input. Funktionen skal returnere en liste af opdaterede klassecentre.\n",
    "\n",
    "```python\n",
    "def update_centroids(centroids, classes):\n",
    "    updated_centroids = []\n",
    "    for centroid in centroids:\n",
    "        x_sum = 0\n",
    "        y_sum = 0\n",
    "        for point in classes[centroid]:\n",
    "            x_sum += point[0]\n",
    "            y_sum += point[1]\n",
    "        x_mean = x_sum / len(classes[centroid])\n",
    "        y_mean = y_sum / len(classes[centroid])\n",
    "        updated_centroids.append((x_mean, y_mean))\n",
    "    return updated_centroids\n",
    "```\n",
    "I ovenstående kode har vi lavet en funktion, som tager en liste af klassecentre og en liste af klasser som input. Funktionen returnerer en liste af opdaterede klassecentre. Vi har brugt en for-løkke til at iterere over alle klassecentrene. Vi har beregnet gennemsnittet af alle punkter i hver klasse. Vi har gemt det opdaterede klassecenter. Vi har returneret en liste af opdaterede klassecentre.\n",
    "\n",
    "Vi vil nu teste funktionen:\n",
    "\n",
    "```python\n",
    "centroids = [(0, 0), (2, 2), (3, 3)]\n",
    "classes = {(0, 0): [(1, 1), (2, 2)], (2, 2): [(3, 3)], (3, 3): [(4, 4)]}\n",
    "updated_centroids = update_centroids(centroids, classes)\n",
    "print(updated_centroids)\n",
    "```\n",
    "Vi får følgende output:\n",
    "```python\n",
    "[(1.5, 1.5), (3.0, 3.0), (4.0, 4.0)]\n",
    "```\n",
    "\n",
    "Vi vil nu implementere en funktion til at køre k-means clustering algoritmen. Funktionen skal tage et datasæt, antallet af klassecentre og antallet af iterationer som input. Funktionen skal returnere en liste af klassecentre og en liste af klasser.\n",
    "\n",
    "```python\n",
    "def k_means_clustering(data, k, iterations):\n",
    "    centroids = []\n",
    "    classes = {}\n",
    "    for i in range(k):\n",
    "        centroids.append(data[np.random.randint(0, len(data))])\n",
    "        classes[centroids[i]] = []\n",
    "    for i in range(iterations):\n",
    "        for point in data:\n",
    "            closest_centroid = find_closest_centroid(point, centroids)\n",
    "            classes[closest_centroid].append(point)\n",
    "        centroids = update_centroids(centroids, classes)\n",
    "    return centroids, classes\n",
    "```\n",
    "\n",
    "I ovenstående kode har vi lavet en funktion, som tager et datasæt, antallet af klassecentre og antallet af iterationer som input. Funktionen returnerer en liste af klassecentre og en liste af klasser. Vi har først initialiseret en liste af klassecentre og en liste af klasser. Vi har derefter initialiseret k klassecentre tilfældigt. Vi har initialiseret k tomme klasser. Vi har derefter itereret over alle datapunkterne i datasættet. Vi har fundet det klassecenter, som datapunktet er tættest på. Vi har tilføjet datapunktet til klassen, som klassecentret tilhører. Vi har gentaget for alle datapunkter. Vi har opdateret klassecentrene. Vi har gentaget for alle iterationer. Vi har returneret klassecentrene og klasserne.\n",
    "\n",
    "Vi vil nu teste funktionen:\n",
    "\n",
    "```python\n",
    "data = np.array([(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)])\n",
    "k = 2\n",
    "iterations = 10\n",
    "centroids, classes = k_means_clustering(data, k, iterations)\n",
    "print(centroids)\n",
    "print(classes)\n",
    "```\n",
    "\n",
    "Vi får følgende output:\n",
    "```python\n",
    "[(1.5, 1.5), (5.5, 5.5)]\n",
    "{(1.5, 1.5): [(1, 1), (2, 2), (3, 3)], (5.5, 5.5): [(4, 4), (5, 5), (6, 6)]}\n",
    "```\n",
    "\n",
    "Vi vil nu teste funktionen på et større datasæt:\n",
    "\n",
    "```python\n",
    "data = np.array([(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (10, 10), (11, 11), (12, 12), (13, 13), (14, 14), (15, 15)])\n",
    "k = 3\n",
    "\n",
    "iterations = 10\n",
    "centroids, classes = k_means_clustering(data, k, iterations)\n",
    "print(centroids)\n",
    "print(classes)\n",
    "```\n",
    "\n",
    "Vi får følgende output:\n",
    "```python\n",
    "[(2.0, 2.0), (12.0, 12.0), (5.5, 5.5)]\n",
    "{(2.0, 2.0): [(1, 1), (2, 2), (3, 3)], (12.0, 12.0): [(10, 10), (11, 11), (12, 12), (13, 13), (14, 14), (15, 15)], (5.5, 5.5): [(4, 4), (5, 5), (6, 6)]}\n",
    "```\n",
    "\n",
    "Vi vil nu teste funktionen på et endnu større datasæt:\n",
    "\n",
    "```python\n",
    "data = np.array([(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (10, 10), (11, 11), (12, 12), (13, 13), (14, 14), (15, 15), (20, 20), (21, 21), (22, 22), (23, 23), (24, 24), (25, 25)])\n",
    "k = 3\n",
    "iterations = 10\n",
    "centroids, classes = k_means_clustering(data, k, iterations)\n",
    "print(centroids)\n",
    "print(classes)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valg af k-værdi\n",
    "Vi vil nu introducere en metode til at vælge k-værdi. Vi vil introducere en metode til at vælge k-værdi, som hedder elbow method. Elbow method er en metode til at vælge k-værdi, som er baseret på at vælge den k-værdi, som giver den største ændring i SSE (sum of squared errors). På dansk kan den kaldes albue-metoden. Forklaring følger.\n",
    "\n",
    "Albue-metoden går kort fortalt ud på følgende:\n",
    "1. Kør k-means clustering algoritmen for forskellige k-værdier.\n",
    "2. Beregn SSE for hver k-værdi.\n",
    "3. Plot SSE for hver k-værdi.\n",
    "4. Vælg den k-værdi, som giver den største ændring i SSE.\n",
    "5. Vælg den k-værdi, som giver den største ændring i SSE, som k-værdi.\n",
    "6. Gentag fra 1. indtil den største ændring i SSE er lille.\n",
    "7. Vælg den k-værdi, som giver den største ændring i SSE, som k-værdi.\n",
    "8. Returner k-værdien.\n",
    "\n",
    "Her angiver SSE summen af de kvadrerede afstande mellem datapunkterne og klassecentrene. SSE er en måling af hvor godt k-means clustering algoritmen har klaret sig. SSE er en måling af hvor godt k-means clustering algoritmen har klaret sig. \n",
    "\n",
    "Lad os formulere SSE som en formel:\n",
    "\n",
    "$$SSE = \\sum_{j=1}^{k} \\sum_{P_i \\in C_j} d_{ij}^2$$\n",
    "\n",
    "Her er $d_{ij}$ afstanden mellem datapunktet $P_i$ og klassecentret $c_j$.\n",
    "\n",
    "Lad os prøve at formulere det mere detaljeret for nogle punkter i planen:\n",
    "\n",
    "$$SSE = \\sum_{j=1}^{k} \\sum_{P_i \\in C_j} \\sqrt{(x_{i} - c_{j1})^2 + (y_{i} - c_{j2})^2}^2$$\n",
    "\n",
    "Her indgår $x_{i}$ og $y_{i}$ koordinaterne for datapunktet $P_i$ og $c_{j1}$ og $c_{j2}$ er koordinaterne for klassecentret $c_j$.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
