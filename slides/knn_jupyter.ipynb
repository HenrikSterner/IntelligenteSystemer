{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduktion til KNN-algoritmen \n",
    "\n",
    "## Af Henrik Sterner (hst@nextkbh.dk)\n",
    "KNN er en af de mest simple algoritmer indenfor maskinelæring. Den er så simpel at den kan implementeres i få linjer kode. Den er dog også en af de mest anvendte algoritmer, og den er en god introduktion til maskinelæring.\n",
    "\n",
    "Grunden til at KNN er så simpel er at den ikke laver nogen form for generalisering. Den gemmer blot alle træningsdata og sammenligner med disse når den skal forudsige en ny værdi.\n",
    "\n",
    "KNN er en såkaldt supervised learning algoritme, hvilket betyder at den skal bruge træningsdata, hvor den kender både input og output. I dette tilfælde er inputtet en vektor af tal, og outputtet er en kategori. Kategorien kunne være om en person er mand eller kvinde, om en blomst er en rose eller en tulipan, eller om en person er syg eller rask. Herunder nogle mulige eksempler på træningsdata:\n",
    "I princippet kan rød eller blå erstatte med 0 eller 1, eller med sand eller falsk, eller alle mulige andre værdier. Eksempler på disse værdier kaldes klasser. De kunne eksempelvis være: \n",
    "- 0 eller 1\n",
    "- sand eller falsk\n",
    "- rød eller blå\n",
    "- mand eller kvinde\n",
    "- kat eller hund\n",
    "- kræft eller ikke kræft\n",
    "- Trump eller Biden\n",
    "- osv.\n",
    "\n",
    "\n",
    "\n",
    "Selvom den er simpel, så er den også en af de mest anvendte algoritmer. Det skyldes at den er hurtig og ofte giver gode resultater. Den er også nem at forstå og nem at implementere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-NN \n",
    "Vi starter med at se på en af de mest simple algoritmer indenfor maskinelæring, nemlig 1-NN.\n",
    "Men det er ikke helt så simpelt som det lyder og det er en god måde at introducere en række begreber på."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudokode for 1-NN fra bunden i planen\n",
    "I det følgende vil vi gennemgå pseudokoden for 1-NN-algoritmen i planen.\n",
    "\n",
    "Betragt nogle punkter i 2D-planen. De er på formen (x,y) og hvert punkt har en farve. Enten rød eller blå.\n",
    "\n",
    "For 1-NN-algoritmen har vi nogle punkter som vi kender farven på. Vi kalder dem træningspunkterne.\n",
    "\n",
    "Målet for 1-NN er at finde farven på et nyt punkt, som vi ikke kender farven på. Vi kalder det for testpunktet.\n",
    "\n",
    "Herunder en forklaring af 1-NN-algoritmen i pseudokode.\n",
    "\n",
    "```python\n",
    "# 1-NN-algoritmen\n",
    "# Input:\n",
    "#   træningspunkter: en liste af punkter med kendt farve\n",
    "#   testpunkt: et punkt som vi ikke kender farven på\n",
    "# Output:\n",
    "#   farven på testpunktet\n",
    "\n",
    "```\n",
    "Herunder i detaljer hvorledes algoritmen fungerer:\n",
    "\n",
    "```python\n",
    "# 1. Beregn afstanden mellem testpunktet og hvert træningspunkt\n",
    "# 2. Find det træningspunkt som er tættest på testpunktet\n",
    "# 3. Returner farven på det træningspunkt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I det følgende vil vi gennemgå koden for 1-NN-algoritmen i planen, hvor vi ikke anvender nogle\n",
    "indbyggede biblioteker herunder numpy, scikit, matplotlib etc. \n",
    "\n",
    "Først genererer vi nogle punkter i 2D-planen. De er på formen (x,y) og hvert punkt har en farve. Enten rød eller blå.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funktion til at generere n punkter i 2D-planen med kendte farver: rød eller blå\n",
    "# Input:\n",
    "#   n: antal punkter\n",
    "# Output:\n",
    "#   liste af punkter\n",
    "#   hvert punkt er en tuple (x,y,color)\n",
    "#   x og y er koordinaterne\n",
    "#   color er farven: 'red' eller 'blue'\n",
    "def generate_points(n):\n",
    "    points = []\n",
    "    for i in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if x + y > 1:\n",
    "            color = 'red'\n",
    "        else:\n",
    "            color = 'blue'\n",
    "        points.append((x,y,color))\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lad os prøve at bruge generate_points af i praksis ved at generere 100 punkter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vi kalder generate_Points funktionen med 100 punkter:\n",
    "points = generate_Points(100)\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vi får brug for en funktion til at visualisere punkterne i 2D-planen. \n",
    "\n",
    "```python\n",
    "# Funktion til at visualisere punkterne i 2D-planen\n",
    "# Input:\n",
    "#   points: liste af punkter\n",
    "# Output:\n",
    "#   ingen (visuelt plot)\n",
    "```\n",
    "Herunder en funktion der visualiserer punkterne i 2D-planen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def plot_points(points):\n",
    "    for point in points:\n",
    "        x = point[0]\n",
    "        y = point[1]\n",
    "        color = point[2]\n",
    "        plt.plot(x,y,'o',color=color)\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Vi genererer nogle punkter og visualiserer dem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "points = generate_points(10)\n",
    "plot_points(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Vi har nu nogle punkter i 2D-planen med kendte farver. Vi kalder dem træningspunkterne.\n",
    "\n",
    "Målet for 1-NN er at finde farven på et nyt punkt, som vi ikke kender farven på. Vi kalder det for testpunktet.\n",
    "\n",
    "Vi genererer et testpunkt og visualiserer det sammen med træningspunkterne:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpoint = generate_points(1)\n",
    "plot_points(points+testpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vi har nu nogle træningspunkter og et testpunkt. Vi vil nu finde farven på testpunktet.\n",
    "\n",
    "Vi starter med at beregne afstanden mellem testpunktet og hvert træningspunkt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distance(point1,point2):\n",
    "    x1 = point1[0]\n",
    "    y1 = point1[1]\n",
    "    x2 = point2[0]\n",
    "    y2 = point2[1]\n",
    "    return math.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi finder det træningspunkt som er tættest på testpunktet:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(points,testpoint):\n",
    "    nearest = points[0]\n",
    "    nearest_distance = distance(points[0],testpoint)\n",
    "    for point in points[1:]:\n",
    "        d = distance(point,testpoint)\n",
    "        if d < nearest_distance:\n",
    "            nearest = point\n",
    "            nearest_distance = d\n",
    "    return nearest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi returnerer farven på det træningspunkt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_color(points,testpoint):\n",
    "    nearest = find_nearest(points,testpoint)\n",
    "    return nearest[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Vi kan nu teste vores 1-NN-algoritme:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(find_color(points,testpoint[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vi kan nu teste vores 1-NN-algoritme på flere testpunkter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpoints = generate_points(10)\n",
    "for testpoint in testpoints:\n",
    "    print(find_color(points,testpoint))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN i planen\n",
    "Herunder gennemgår vi K-NN i planen. Vi starter med at importere de nødvendige biblioteker.\n",
    "\n",
    "\n",
    "## Pseudokode for K-NN (K-Nærmeste Naboer) fra bunden i planen\n",
    "I det følgende vil vi gennemgå koden for KNN-algoritmen i planen.\n",
    "\n",
    "Betragt nogle punkter i 2D-planen. De er på formen (x,y) og hvert punkt har en farve. Enten rød eller blå. \n",
    "\n",
    "Vi har nogle punkter som vi kender farven på. Vi kalder dem træningspunkterne. \n",
    "\n",
    "Målet for KNN er at finde farven på et nyt punkt, som vi ikke kender farven på. Vi kalder det for testpunktet.\n",
    "\n",
    "Herunder en forklaring af KNN-algoritmen i pseudokode. \n",
    "\n",
    "```python\n",
    "# KNN-algoritmen\n",
    "# Input:\n",
    "#   træningspunkter: en liste af punkter med kendt farve\n",
    "#   testpunkt: et punkt som vi ikke kender farven på\n",
    "#   k: antal punkter vi vil sammenligne med\n",
    "# Output:\n",
    "#   farven på testpunktet\n",
    "\n",
    "```\n",
    "Herunder i detaljer hvorledes algoritmen fungerer:\n",
    "\n",
    "```python\n",
    "# 1. Beregn afstanden mellem testpunktet og hvert træningspunkt\n",
    "# 2. Sorter træningspunkterne efter afstand til testpunktet\n",
    "# 3. Vælg de k nærmeste træningspunkter\n",
    "# 4. Tæl antallet af røde og blå punkter blandt de k nærmeste\n",
    "# 5. Hvis der er flere røde end blå punkter, returner rød\n",
    "# 6. Ellers returner blå\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation af KNN i Python fra bunden\n",
    "I det følgende vi implementere KNN-algoritmen i Python i 2d fra bunden. .\n",
    "\n",
    "Vi starter med at importere de nødvendige biblioteker:\n",
    "```python\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "Vi definerer en funktion til at generere tilfældige punkter i 2d:\n",
    "\n",
    "```python\n",
    "def generate_points(n):\n",
    "    points = []\n",
    "    for i in range(n):\n",
    "        x = random.uniform(-1,1)\n",
    "        y = random.uniform(-1,1)\n",
    "        points.append((x,y))\n",
    "    return points\n",
    "\n",
    "Vi bemærker, at random.uniform returnerer et tal mellem -1 og 1. Vi kan derfor bruge den til at generere en liste af tal mellem -1 og 1. \n",
    "\n",
    "Lad os afprøve funktionen:\n",
    "```python\n",
    "points = generate_points(10)\n",
    "print(points)\n",
    "```\n",
    "Vi kan nu visualisere punkterne i et koordinatsystem:\n",
    "```python\n",
    "def plot_points(points):\n",
    "    x = [p[0] for p in points]\n",
    "    y = [p[1] for p in points]\n",
    "    plt.scatter(x,y)\n",
    "    plt.show()\n",
    "```\n",
    "Vi kan nu afprøve funktionen:\n",
    "```python\n",
    "plot_points(points)\n",
    "```\n",
    "\n",
    "Vi kan nu generere to lister af punkter, som vi kan bruge til at træne vores KNN-algoritme på. Vi genererer 1000 punkter i hver liste:\n",
    "```python\n",
    "points1 = generate_points(1000)\n",
    "points2 = generate_points(1000)\n",
    "```\n",
    "\n",
    "Vi kan nu visualisere de to lister af punkter:\n",
    "```python\n",
    "plot_points(points1)\n",
    "plot_points(points2)\n",
    "```\n",
    "\n",
    "Vi kan nu definere en funktion til at beregne afstanden mellem to punkter:\n",
    "```python\n",
    "def distance(p1,p2):\n",
    "    return math.sqrt((p1[0]-p2[0])**2+(p1[1]-p2[1])**2)\n",
    "```\n",
    "\n",
    "Vi kan nu afprøve funktionen:\n",
    "```python\n",
    "print(distance((0,0),(1,1)))\n",
    "```\n",
    "\n",
    "Vi kan nu definere en funktion til at finde de k nærmeste naboer til et punkt:\n",
    "```python\n",
    "def find_k_nearest_neighbors(p,points,k):\n",
    "    distances = []\n",
    "    for point in points:\n",
    "        distances.append((distance(p,point),point))\n",
    "    distances.sort()\n",
    "    return distances[:k]\n",
    "```\n",
    "Her sørger sort for at sortere listen af tupler efter den første værdi i tuplen, som er afstanden. Vi kan nu afprøve funktionen:\n",
    "```python\n",
    "print(find_k_nearest_neighbors((0,0),points1,5))\n",
    "```\n",
    "\n",
    "Vi kan nu definere en funktion til at finde den hyppigste klasse blandt de k nærmeste naboer:\n",
    "```python\n",
    "def find_most_frequent_class(neighbors):\n",
    "    classes = {}\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor[1] in classes:\n",
    "            classes[neighbor[1]] += 1\n",
    "        else:\n",
    "            classes[neighbor[1]] = 1\n",
    "    return max(classes, key=classes.get)\n",
    "```\n",
    "I denne kode bruger vi en dictionary til at tælle antallet af forekomster af hver klasse. Vi bruger max til at finde den klasse, som optræder flest gange.\n",
    "\n",
    "Vi kan nu afprøve funktionen:\n",
    "```python\n",
    "print(find_most_frequent_class(find_k_nearest_neighbors((0,0),points1,5)))\n",
    "```\n",
    "\n",
    "Så er vi endelig klar til at definere vores KNN-algoritme:\n",
    "```python\n",
    "def knn(p,points,k):\n",
    "    neighbors = find_k_nearest_neighbors(p,points,k)\n",
    "    return find_most_frequent_class(neighbors)\n",
    "```\n",
    "\n",
    "Vi kan nu afprøve funktionen:\n",
    "```python\n",
    "print(knn((0,0),points1,5))\n",
    "```\n",
    "eller\n",
    "```python\n",
    "print(knn((0,0),points2,5))\n",
    "```\n",
    "\n",
    "Vi bemærker, at vi undervejs har løst problemet ved at opdele det i mindre delproblemer, som vi har løst enkeltvis. Dette er en generel strategi, som vi vil bruge igen og igen.\n",
    "Det ses bl.a. ved at vi har defineret funktioner for at løse delproblemerne. Det er en god ide at opdele problemer i mindre delproblemer, da det ofte gør det nemmere at løse dem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation af K-NN ved brug af numpy, matplotlib og scipy\n",
    "I denne notebook vil vi implementere K-NN algoritmen ved brug af numpy, matplotlib og scipy. Vi vil bruge en række af de funktioner som vi har introduceret tidligere. Vi vil også introducere en række nye funktioner.\n",
    "\n",
    "Vi vil bruge følgende notation: \n",
    "- $X$ er en matrix med $n$ rækker og $m$ kolonner. \n",
    "- $x$ er en vektor med $m$ elementer. \n",
    "- $y$ er en vektor med $n$ elementer.\n",
    "- $x_i$ er en vektor med $m$ elementer.\n",
    "- $y_i$ er en skalar.\n",
    "- $x_{ij}$ er en skalar.\n",
    "- $y_{i}$ er en skalar.\n",
    "\n",
    "Lad os først foretage de nødvendige importeringer:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "```\n",
    "\n",
    "Herunder en række hjælpefunktioner, som blot angiver nogle forskellige måder at beregne distancen mellem to vektorer på:\n",
    "\n",
    "```python\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "def manhattan_distance(x1, x2):\n",
    "    return np.sum(np.abs(x1 - x2))\n",
    "\n",
    "def cosine_distance(x1, x2):\n",
    "    return 1 - np.dot(x1, x2) / (np.sqrt(np.dot(x1, x1)) * np.sqrt(np.dot(x2, x2)))\n",
    "\n",
    "def hamming_distance(x1, x2):\n",
    "    return np.sum(x1 != x2)\n",
    "\n",
    "def minkowski_distance(x1, x2, p):\n",
    "    return np.sum(np.abs(x1 - x2)**p)**(1/p)\n",
    "```\n",
    "\n",
    "Lad os nu formulere K-NN algoritmen:\n",
    "\n",
    "```python\n",
    "def knn(X_train, y_train, x_test, k, distance_metric):\n",
    "    distances = []\n",
    "    for i in range(len(X_train)):\n",
    "        distances.append(distance_metric(X_train[i], x_test))\n",
    "    distances = np.array(distances)\n",
    "    k_nearest = np.argsort(distances)[:k]\n",
    "    k_nearest_labels = y_train[k_nearest]\n",
    "    return np.bincount(k_nearest_labels).argmax()\n",
    "```\n",
    "Her er distance_metric en funktion som tager to vektorer som input og returnerer en skalar, distances et array med afstande fra x_test til alle punkter i X_train, k_nearest et array med de k nærmeste punkter i X_train og k_nearest_labels et array med de tilhørende labels.\n",
    "\n",
    "Lad os nu teste vores K-NN algoritme på Iris-datasættet:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "```\n",
    "\n",
    "Vi vil nu opdele datasættet i et træningssæt og et testsæt:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "```\n",
    "\n",
    "Vi vil nu teste vores K-NN algoritme på et enkelt punkt:\n",
    "\n",
    "```python\n",
    "x_test = X_test[0]\n",
    "y_test = y_test[0]\n",
    "knn(X_train, y_train, x_test, 5, euclidean_distance)\n",
    "```\n",
    "\n",
    "Vi vil nu teste vores K-NN algoritme på alle punkter i testsættet:\n",
    "\n",
    "```python\n",
    "y_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    y_pred.append(knn(X_train, y_train, X_test[i], 5, euclidean_distance))\n",
    "y_pred = np.array(y_pred)\n",
    "```\n",
    "\n",
    "Vi vil nu beregne nøjagtigheden af vores K-NN algoritme:\n",
    "\n",
    "```python\n",
    "np.sum(y_pred == y_test) / len(y_test)\n",
    "```\n",
    "\n",
    "Vi vil nu visualisere vores K-NN algoritme:\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap='rainbow')\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='rainbow')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Vi vil nu visualisere vores K-NN algoritme med en contour plot:\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap='rainbow')\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='rainbow')\n",
    "plt.contourf(X_test[:, 0], X_test[:, 1], y_pred, alpha=0.2, cmap='rainbow')\n",
    "plt.show()\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
